{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer: if you want to use the data scraped by running this notebook to build an actual product/service you need to contact vg.no as this data is owned by them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to find a new tag, vist an article with the tag you're interested in, click the tag at the end of the article, and it should be visible in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_tags = {\n",
    "    \"krim\": \"9711b2e2-b098-48aa-98d4-5dfc0244e289\",\n",
    "    \"politikk\": \"e8c7541a-9618-4992-a5d0-5607fd771248\",\n",
    "    \"vær\": \"a385212b-72cc-4dcf-baad-9c916f7ccd7c\",\n",
    "    \"sjakk\": \"315ad1d0-7176-46fa-a592-bccd02216a71\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_url_template = \"https://www.vg.no/iris/v1/teasers?offset={offset}&limit={limit}&section=&excludedSections=&tag={tag}&story=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the articles for one particular tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_urls(tag, num, batch_size=100):\n",
    "    num_yielded = 0\n",
    "    while num_yielded < num:\n",
    "        articles_request = articles_url_template.format(\n",
    "            offset=num_yielded,\n",
    "            limit=batch_size,\n",
    "            tag=tag\n",
    "        )\n",
    "        response = requests.get(articles_request)\n",
    "        try:\n",
    "            articles = response.json()[\"articles\"]\n",
    "            if not articles:\n",
    "                return\n",
    "        except KeyError:\n",
    "            return\n",
    "        for a in articles:\n",
    "            yield a[\"links\"][\"canonicalUrl\"]\n",
    "            num_yielded += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and parse the article found at the given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    body = \"\"\n",
    "    article = soup.find(\"article\")\n",
    "    if article is not None:\n",
    "        for text_part in article.find_all(re.compile(\"^(?:h\\d|p)$\")):\n",
    "            body += text_part.text + \"\\n\"\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store articles in this dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data/vg_nyheter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To find the actual article corresponding to the scraped article, visit https://www.vg.no/i/<article_id>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_articles(tags_dict, num_articles_per_tag):\n",
    "    for tag_name, tag in tags_dict.items():\n",
    "        tag_dir = data_dir / tag_name\n",
    "        if not tag_dir.is_dir():\n",
    "            tag_dir.mkdir(parents=True)\n",
    "        print(f\"Fetching articles for tag {tag_name} \")\n",
    "        for url in get_article_urls(tag, num_articles_per_tag):\n",
    "            print(\".\", end=\"\")\n",
    "            article_id = re.search(\"/i/(?P<id>\\w+)/\", url).group(\"id\")\n",
    "            article_file = tag_dir / (article_id + \".txt\")\n",
    "            if not article_file.is_file():\n",
    "                article_body = parse_article(url)\n",
    "                with open(article_file, \"w\", encoding=\"utf8\") as f:\n",
    "                    f.write(article_body)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching articles for tag krim \n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Fetching articles for tag politikk \n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Fetching articles for tag vær \n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Fetching articles for tag sjakk \n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "fetch_articles(topic_tags, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
